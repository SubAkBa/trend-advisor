# Trend Advisor
트렌드 키워드 예측을 통한 온라인 스토어팜 가이드

## 1. 자바를 이용하여 네이버 데이터랩 랭킹 키워드, 18년도 6월 네이버 뉴스 기사 데이터 수집

## 2. 뉴스 기사 전처리

- 기사 내용 요약 (Summarization) -> LexRank (TF-IDF + Cosine Similarity) 사용
- 요약된 문장 2개를 형태소 분석 파싱 이용하여 명사, 형용사, 부사 추출 (Extraction)
- User Dictionary를 이용하여 아이템 키워드 필터링

## 3. 최종 Output

- 뉴스기사, 데이터랩 각 카테고리의 랭킹 키워드를 추출
- 각 키워드의 점수를 합산하여 최종적으로 점수에 대해 내림차순으로 정렬한 랭킹 키워드 생성

## 4. 파일 설명

- naver-datalab-extractor 폴더 : 자바 데이터 수집  
- 판매량,랭크상관관계분석 폴더 : '랭크와 판매량이 서로 관계가 있을 것이다' 라는 명제에 대해 관계를 증명하기 위해 분석한 폴더  
- web-project : 서비스를 제공하기 위해 구축한 웹 프로젝트 파일  
- text-export : Python을 이용하여 여러 시도 (감성 분석, 요약 [TextRank, LexRank], 키워드 사전)  
- add_product_keyword.R : 사전 최적화를 위해 여러 아이템 키워드 데이터를 합치는 코드 파일  
- article_result_06[주].csv : 각 주차의 최종 output 결과 데이터  
- connect_mysql.R : 최종 output 데이터를 AWS 내 mysql 데이터베이스에 삽입하기 위한 코드 파일  
- encoding.sh : 수집한 네이버 기사 json 데이터에 대해 발생한 인코딩 오류를 한꺼번에 처리하기 위한 쉘 코드 파일  
- file_preprocessing.R : R을 이용하여 크롤링한 기사 데이터에 대해 전처리 하고 분포를 확인하기 위한 코드 파일  
- kyunghyang_article_crawling.R : 경향신문기사 데이터를 크롤링 하기 위한 코드 파일  
- naver_lifearticle_crawling.R : 네이버 생활 카테고리 기사를 크롤링 하기 위한 코드 파일  
  
## 5. 어려웠던 점

### 5-1.
- 현재 네이버 데이터랩에서는 판매량 데이터를 제공해주지 않기 때문에 유사한 판매량 데이터를 얻기위해 옥션, 지마켓등의 쇼핑몰데이터를 크롤링하여 사용함.
- 쇼핑몰 데이터를 사용하지만 데이터 자체도 지저분하고 정확하지 않음. 광고의 영향을 받아 랭킹이 바뀔 수도 있으며, 표시되어 있는 판매량의 데이터가 실제 판매량인지 알 수 없으며, 그 판매량이 하루 판매량이 아닌 누적 판매량일것으로 생각.
- 하루당 판매량을 알기 위해서 날짜별로 판매량을 뺌. 30일 데이터와 29일 데이터에서 랭킹 별로 판매량을 뺌.
     - 문제점 : 판매량을 뺏을 때 음수가 나오는 경우가 대부분이였음. 그렇다면 환불한 경우인가?
     - 해결책 : 판매량이 아닌 총 거래량으로 보자고 생각을 하여 모두 절댓값을 씌움. 어쨋든 키워드는 이 물품이 팔리던 안팔리던 검색한 횟수를 통해 랭킹이 올라간다고 생각.
     - 문제점 : 판매량을 뺏을 때 그 차이가 엄청난 경우가 있었음. 예를 들어, 29일날 판매량이 100개인데 30일날 12만개가 팔린 데이터가 있었으며, 이러한 경우 그 전에 누적되어 많이 팔렸던 회사가 30일날 포함되어져온다고 판단했음. 이 반대의 경우도 있음.
     - 해결책 : 어떠한 기준값을 잡아 그것보다 크거나 -기준값보다 작다면 해당 데이터는 이상치라고 판단하여 제거하기로 결정  
     
### 5-2.
- 랭킹별로 연산을 진행하는 것이 아닌 동일한 물품으로 거래량을 계산해보기로 하였음. 그리고 이 물품이 전날 랭킹에서 얼마나 바뀌었는지 랭킹변화량을 계산하여 사용하기로 했음. 
     - 문제점 : outlier를 제거했을 때 회귀계수는 p-value가 0.05이내로 들어오지만 y절편은 만족하지 못함.
     - 해결책 : 누적판매량 - 누적판매량은 당일날의 순수 판매량이기 때문에 랭킹 변화량과 상관관계를 알아보기 위해서는 순수 판매량 - 순수 판매량을 한번 더 해줌.

### 5-3.
- LSTM + Pairwise를 통해 시간 데이터를 이용하여 output으로 키워드를 뽑아주려고 하였음. (LSTM 사용이유 : 시간 순서대로 데이터를 집어넣어 미래의 데이터를 예측하기 위해, Pairwise : 최종 output은 여러 키워드들이고 classification이 아닌 새로 생기는 키워드까지 예측하기 위해서)
  - 문제점 : LSTM의 input으로 랭크 키워드를 집어넣어야 하고 그렇다면 문장 형식으로 집어넣어야 하는데 input은 문장 형식이지만 서로 관계가 없는 단어들이고 결국 의미있게 학습이 되지 않을거라 판단
	- 해결책 : 다른 언어 모델을 이용
 
### 5-4.
- 최신 모델인 BERT를 이용하여 질문답변의 형식으로 데이터를 만들고 진행하려고 하였음.
	- 문제점 : 위의 문제점과 마찬가지로 input을 만들기 어렵다고 판단
	- 해결책 : 딥러닝 모델을 쓰는 것이 아닌 우리가 원하는 형태의 알고리즘으로 input을 생성

### 5-5.
- 뉴스, 네이버 데이터 랩 키워드를 사용하는데 뉴스와 sns는 기사내에서 가장 빈출이 많이 되는 단어들을 랭킹순으로 나열 (1주간의 데이터 취합) 후 뉴스, 데이터 랩 랭킹 키워드들의 빈출도를 합치고 각 카테고리별로 가중치를 입혀 최종적인 예측 랭킹 키워드들을 output으로 출력.
	- 문제점 : 뉴스 데이터 내에서 가장 빈출되는 단어를 미래에 트랜드가 될 키워드로 지정하기엔 허점이 너무 많음. 그리고 우리의 목적은 창업의 아이템 키워드를 뿌려줘야 하는데 그러한 키워드가 아닌 사람이름, 지역이름 등이 될 수도 있음.
	- 해결책 : 한 기사에서 요약 문장을 낸 다음, 형태소분석을 통해 뽑은 아이템 키워드를 사용함.
  
### 5-6.
- 기사, 데이터랩을 통해 나온 랭킹 키워드들을 합쳐 최종 output을 내야함.
	- 문제점 : 랭킹 키워드의 개수가 다르기 때문에 동일한 분포로 만든 후 점수를 더해야 함.
	- 해결책 : 각 랭킹 키워드의 갯수만큼 0 ~ 1사이로 스케일링 한 후 점수를 합산하여 최종 랭크 점수 획득.
  
### 5-7.
- SNS 데이터도 수집해보려 하였지만 다른 유저들의 데이터는 모을 수 없었음.

## 6. 발전 가능성
- 현재 한국어만 요약 및 예측 가능하기 때문에 추후에는 영어, 일본어 등 외국어에 대한 키워드도 추출할 수 있도록 개발.
- 판매에 영향을 미치는 데이터는 많지만 시간이 부족하여 일부 데이터만 취하여 아이템 키워드 예측. 다양한 데이터를 수집할 필요가 있음.
- 매주차가 끝날 때마다 자동적으로 데이터를 모으고 분석하여 예측한 뒤의 output을 데이터베이스에 저장하는 것도 고려.
- 아이템 키워드 사전 최적화.
